{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4db3049",
   "metadata": {
    "id": "d4db3049"
   },
   "source": [
    "# **Introduction to Deep Computer Vision**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8ee31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is running from: c:\\Users\\jinny\\.conda\\envs\\gpu\\python.exe\n",
      "TensorFlow version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Python is running from:\", sys.executable)\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1d61ba",
   "metadata": {
    "id": "ec1d61ba"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1OG7xluBTNL7",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765982747154,
     "user": {
      "displayName": "Niphat Craypho",
      "userId": "01495670548613215475"
     },
     "user_tz": -420
    },
    "id": "1OG7xluBTNL7"
   },
   "outputs": [],
   "source": [
    "# Mount the files from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JrCKgA2VGqu0",
   "metadata": {
    "id": "JrCKgA2VGqu0"
   },
   "source": [
    "#**Image Classification using Tensorflow Kreas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2H23EPYaQs7v",
   "metadata": {
    "id": "2H23EPYaQs7v"
   },
   "source": [
    "## **Prepare Flower Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731f5c87",
   "metadata": {
    "id": "731f5c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 880 images belonging to 5 classes.\n",
      "Found 96 images belonging to 5 classes.\n",
      "Found 976 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set image size and other parameters\n",
    "IMAGE_SIZE = 50\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)  # Adjust based on your dataset image size\n",
    "target_size = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "batch_size = 4\n",
    "num_classes = 5  # 5 flower categories: daisy, dandelion, rose, sunflower, tulip\n",
    "\n",
    "# Image Data Augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,          # Normalize pixel values\n",
    "    validation_split = 0.1\n",
    "    # rotation_range=20,          # Randomly rotate images\n",
    "    # width_shift_range=0.2,      # Horizontal shift\n",
    "    # height_shift_range=0.2,     # Vertical shift\n",
    "    # shear_range=0.2,            # Shear transformation\n",
    "    # zoom_range=0.2,             # Random zoom\n",
    "    # horizontal_flip=True,       # Flip images horizontally\n",
    "    # fill_mode='nearest'         # Fill missing pixels after transformation\n",
    ")\n",
    "\n",
    "path_to_train_data = r'C:\\Users\\jinny\\Desktop\\cv\\flower dataset\\train'\n",
    "\n",
    "# Create the training generator(90%)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path_to_train_data,       # Set the path to your training dataset (5 folders)\n",
    "    target_size= target_size,     # Resize images to match input_shape\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',    # Multiclass classification\n",
    "    subset = 'training'\n",
    "\n",
    ")\n",
    "#Create the validation generator(10%)\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "#####=====Enter your program code here. =====#####\n",
    "    path_to_train_data,       \n",
    "    target_size= target_size,    \n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',    \n",
    "    subset = 'validation'\n",
    "\n",
    ")\n",
    "\n",
    "# Image Data Augmentation for validation data (only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load validation data\n",
    "path_to_validation_data = r'C:\\Users\\jinny\\Desktop\\cv\\flower dataset\\train'\n",
    "\n",
    "#Create the test generator\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "#####=====Enter your program code here. =====#####\n",
    "    path_to_validation_data,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode= None\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate validation steps\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "l-C9sQdLUZZI",
   "metadata": {
    "id": "l-C9sQdLUZZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train (4, 50, 50, 3), y train (4, 5)\n"
     ]
    }
   ],
   "source": [
    "batch_train = train_generator.__next__()\n",
    "x_batch, y_batch = batch_train\n",
    "print(f\"x train {x_batch.shape}, y train {y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7q_JR0g-XNV8",
   "metadata": {
    "id": "7q_JR0g-XNV8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x test: (4, 50, 50, 3), label [[0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "batch_test  = valid_generator.__next__()\n",
    "x_batch, y_test = batch_test\n",
    "print(f\"x test: {x_batch.shape}, label {y_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9Z4Sm9XjZMvm",
   "metadata": {
    "id": "9Z4Sm9XjZMvm"
   },
   "source": [
    "## **Create your CNNs model** </font>\n",
    "#Convolution -> ReLU -> Pooling -> Flatten -> Dense -> Output ->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "p5jmDNVQTrNL",
   "metadata": {
    "id": "p5jmDNVQTrNL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4719616   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 5125      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,817,989\n",
      "Trainable params: 4,817,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 23s 55ms/step - loss: 1.5023 - accuracy: 0.3375 - val_loss: 1.2909 - val_accuracy: 0.4167\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 1.2301 - accuracy: 0.5045 - val_loss: 1.1294 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 1.0851 - accuracy: 0.5557 - val_loss: 1.1942 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.9719 - accuracy: 0.6341 - val_loss: 1.1950 - val_accuracy: 0.5312\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.9022 - accuracy: 0.6523 - val_loss: 0.9060 - val_accuracy: 0.6771\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 2s 8ms/step - loss: 0.7985 - accuracy: 0.6898 - val_loss: 0.7710 - val_accuracy: 0.6979\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.6361 - accuracy: 0.7591 - val_loss: 0.9454 - val_accuracy: 0.6771\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.5916 - accuracy: 0.8045 - val_loss: 1.1238 - val_accuracy: 0.6458\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.4308 - accuracy: 0.8284 - val_loss: 1.0031 - val_accuracy: 0.6458\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.3602 - accuracy: 0.8773 - val_loss: 0.9079 - val_accuracy: 0.6771\n"
     ]
    }
   ],
   "source": [
    "# Enter the code as follows:\n",
    "# Build the Deep Convolutional Neural Network\n",
    "\n",
    "# Step1: Create sequential stack of layers into a model\n",
    "model = Sequential()\n",
    "\n",
    "# Step2: First Convolutional Block\n",
    "model.add(Conv2D(32, (3,3), activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# Setp3 Second Convolutional Block\n",
    "model.add(Conv2D(64, (3,3),\n",
    "                 activation='relu',\n",
    "                 padding='same'\n",
    "                 \n",
    "                 ))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Step4: Third Convolutional Block\n",
    "model.add(Conv2D(128, (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Step5: Flatten and Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Step6: Define the Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Step7: Compile the Model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "\n",
    "              )\n",
    "\n",
    "# EarlyStopping based on accuracy reaching 80%\n",
    "early_stop_accuracy = EarlyStopping(\n",
    "    monitor='accuracy',        # Monitor accuracy during training\n",
    "    baseline=0.01,             # Target accuracy (90%)\n",
    "    patience=5,                # Stop if no improvement after reaching 90% accuracy\n",
    "    restore_best_weights=True  # Restore the model weights at the highest accuracy\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Step8: Train the model with EarlyStopping\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs = 10,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks = [early_stop_accuracy]\n",
    ")\n",
    "\n",
    "# Step9: Save the model\n",
    "model.save('flower_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b69b31",
   "metadata": {
    "id": "68b69b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 9ms/step - loss: 0.9079 - accuracy: 0.6771\n",
      "Validation Accuracy: 67.71%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "loss, accuracy = model.evaluate(valid_generator)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rvi2Et2YrmTO",
   "metadata": {
    "id": "rvi2Et2YrmTO"
   },
   "source": [
    "# **Classify unseen data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4734fae",
   "metadata": {
    "id": "b4734fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step\n",
      "Predicted class: Tulip\n"
     ]
    }
   ],
   "source": [
    " #####===== Enter your code program. =====#####\n",
    "# Load the trained model\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path): # For unseen data\n",
    "\n",
    "    # Step1: Load images for directory path and resize image to match the input shape of the model\n",
    "    img_array = image.load_img(\n",
    "        img_path,\n",
    "        target_size = target_size\n",
    "    )\n",
    "\n",
    "    # Step2: Convert the image to a NumPy array\n",
    "    img_array = image.array_to_img(img_array)\n",
    "    # Step3: Add a batch dimension (for a single image)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Step4: Normalize the image (same normalization used during training)\n",
    "    img_array = img_array/255.0\n",
    "    # Step5: return image\n",
    "    return img_array\n",
    "\n",
    "# Path to the image you want to classify\n",
    "img_path = r'C:\\Users\\jinny\\Desktop\\cv\\flower dataset\\test\\Image_6.jpg'\n",
    "\n",
    "# Preprocess the image\n",
    "pre_data = preprocess_image(img_path)\n",
    "\n",
    "# Use the model to predict the class\n",
    "predicted_class = model.predict(pre_data)\n",
    "\n",
    "# Get the index of the highest probability class\n",
    "predicted_class = np.argmax(predicted_class)\n",
    "\n",
    "# Class labels (corresponding to the order of your folder structure during training)\n",
    "class_labels = ['Daisy', 'Dandelion', 'Rose', 'Sunflower', 'Tulip']\n",
    "\n",
    "# Print the predicted class\n",
    "print(f\"Predicted class: {class_labels[predicted_class]}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
